---
title: "SDS 315 - Homework 3"
author: "Kavya Chowti - kc45736"
date: "2024-02-04"
output: html_document
---

```{r global options,  echo=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=7, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60))
```

[Hyperlink to Github Repository](https://github.com/KavyaChowti/SDS_315_Homework_3)

***

# **Question 1**

```{r echo=FALSE, message=FALSE}

creatinine = read.csv("creatinine.csv")
attach(creatinine)

```


#### **PART A**
```{r echo=FALSE, message=FALSE,  results='hide'}

# make a linear model comparing age to the creatinine clearance rate
creatinine_lm <- lm(creatclear ~ age, data = creatinine)
summary(creatinine_lm)

# Predict creatinine clearance rate for a 55-year-old
creatinine_new <- data.frame(age = 55)
predicted_clearance <- predict(creatinine_lm, newdata = creatinine_new)
predicted_clearance
147.81292+(-0.61982*55)
```

For a 55 year old, we can expect a creatinine clearance rate of 113.723 mL/min. I determined this by first creating a linear model comparing the age of each patient in the data to their cleared creatinine rate. After, I used the summary of the linear model with the rate of change to estimate what the expected clearance rate for a 55 year old patient would be which was about 147.81292 + (-0.61982 * 55) = 113.723 mL/min.


#### **PART B**
```{r echo=FALSE, message=FALSE, results='hide'}

# Extract the slope coefficient from the linear regression model
slope <- coef(creatinine_lm)["age"]
slope

```

The creatinine clearance rate decreases by about 0.6198159 mL/min on average per year of age that a patient gains. After making a linear model, I determined this by looking at the coefficient for the slope, how much on average the clearance rate changed per year of age which was -0.6198159.


#### **PART C**

```{r echo=FALSE, message=FALSE, results='hide'}

# Predict clearance rates for the given ages
clearance_40 <- predict(creatinine_lm, newdata = data.frame(age = 40))
clearance_60 <- predict(creatinine_lm, newdata = data.frame(age = 60))
clearance_40
clearance_60

# Compare the observed rates with the predicted rates
observed_clearance_40 <- 135
observed_clearance_60 <- 112


```

To find the expected creatinine clearance rates for a 40 and 60 year old I used the equation 
147.81292 + (-0.61982 * age) = expected clearance rate to find that they were 123.0203 mL/min and 110.624 mL/min respectively. After comparing them with the observed values we see that while both residuals are positive, the residual for the 40 year old is higher meaning that they had a higher than expected clearance rate compared to the 60 year old and since in this context, higher numbers mean healthier, the 40 year old is healthier.

***

# **Question 2**


```{r echo=FALSE, message=FALSE}

market = read.csv("marketmodel.csv")
attach(market)

```


The beta (β) of a stock is a metric that measures the stock's sensitivity to market movements. Specifically, beta quantifies the stock's exposure to systematic risk, which is the risk associated with overall market fluctuations. Calculation of the beta (β) value involves performing a linear regression of an individual stock's rate of return (Y) compared to the rate of return of the overall stock market (X). By setting the rate of of return on an individual stock equal to the rate of return of the overall market added to the intercept (the return on the individual stock when the overall market is 0) as well as the residual for that stock in the time period, we can find the beta value of the stock by identifying the slope value of the rate of return for the overall market.  
The video emphasizes the division of risk into unsystematic (firm-specific) and systematic (market-related) components. The beta is presented as a measure of systemic risk, reflecting how a stock's return responds to a 1% change in the overall market return. A beta of 1.0 indicates that the stock tends to move in tandem with the market, while a beta less than 1.0 suggests lower systemic risk, and a beta greater than 1.0 indicates higher systemic risk. In connection to the Capital Asset Pricing Model (CAPM) regression equation, the video connects the beta (slope term) to the model's assumptions. A beta less than 1.0, exemplified by firms like Bank of America and Walmart, implies lower systemic risk than the average firm. Conversely, firms with a beta greater than 1.0, such as Amazon, indicate higher susceptibility to market movements. Additionally, the video introduces the concept of negative beta, which indicates a negative risk premium. A negative beta implies that the firm performs well when the market declines. 

```{r echo=FALSE, message=FALSE}

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Initialize vectors to store results
tickers <- c()
intercepts <- c()
slopes <- c()
r_squared_values <- c()

# Loop through each stock and perform regression
stocks <- c("AAPL", "GOOG", "MRK", "JNJ", "WMT", "TGT")
for (stock in stocks) {
  # Select data for the current stock
  stock_data <- data.frame(Y = market[[stock]], X = market$SPY)
  
  # Perform linear regression
  market_regression_model <- lm(Y ~ X, data = stock_data)
  
  # Extract relevant information
  intercept <- round(coef(market_regression_model)[1], 5)
  slope <- round(coef(market_regression_model)[2], 5)
  r_squared <- round(summary(market_regression_model)$r.squared, 5)
  
  # Append results to vectors
  tickers <- c(tickers, stock)
  intercepts <- c(intercepts, intercept)
  slopes <- c(slopes, slope)
  r_squared_values <- c(r_squared_values, r_squared)
}

# Create a data frame from the vectors
market_regression_results_df <- data.frame(Ticker = tickers, Intercept = intercepts, Slope = slopes, R2 = r_squared_values, stringsAsFactors = FALSE)

# Create a kable table
market_regression_results_df %>%
  kbl() %>%
  kable_styling(full_width = T, position = "left") %>%
  column_spec(1, bold = TRUE)


```

This table presents the results of linear regressions for individual stocks against the rate of return of the S&P 500 stock index (denoted as SPY) where each row corresponds to a specific stock, including Apple (AAPL), Google (GOOG), Merck (MRK), Johnson and Johnson (JNJ), Walmart (WMT), and Target (TGT). There are 4 columns which are Ticker (the unique symbol representing each stock), Intercept (the intercept term β₀ in the linear regression equation which indicates the expected rate of return when the market return SPY is zero), Slope (the slope term β₁ represents the sensitivity of the stock's rate of return to changes in the overall market return SPY), and R² (measures the proportion of variability in the stock's return explained by the linear regression model). The regressions provide insights into how each stock's return relates to the overall market.

**Conclusion**

Based on the analysis, Walmart has the lowest systematic risk with a β-value of 0.51898 meaning that for every one percent increase or decrease in the overall market, Walmart's return only increases or decreases by 0.51898 respectively. Since it is below 1.0, Walmart is lower than the average company.   Apple has the highest systematic risk with a β-value of 1.06560 meaning that for every one percent increase or decrease in the overall market, Apple's return  increases or decreases by 1.06560 respectively. Since it is above 1.0, Apple has a higher systematic risk than the average company.

***

# **Question 3**


```{r echo=FALSE, message=FALSE}

# Load required packages
library(ggplot2)
library(minpack.lm)

# Read the data
covid_data <- read.csv("covid.csv")
attach(covid_data)

# Filter data for Italy and Spain
italy_data <- subset(covid_data, country == "Italy")
spain_data <- subset(covid_data, country == "Spain")

# Fit exponential growth models using minpack.lm
italy_model <- nlsLM(deaths ~ exp(log(2) * days_since_first_death * r), data = italy_data, start = list(r = 0.01))
spain_model <- nlsLM(deaths ~ exp(log(2) * days_since_first_death * r), data = spain_data, start = list(r = 0.01))

# Extract growth rates
italy_growth_rate <- coef(italy_model)[['r']]
spain_growth_rate <- coef(spain_model)[['r']]

# Calculate doubling times
italy_doubling_time <- round(70 / (italy_growth_rate * 100))
spain_doubling_time <- round(70 / (spain_growth_rate * 100))

# Create a line graph
ggplot() +
  geom_line(data = italy_data, aes(x = days_since_first_death, y = deaths, color = "Italy"), size = 1) +
  geom_line(data = spain_data, aes(x = days_since_first_death, y = deaths, color = "Spain"), size = 1) +
  labs(x = "Days Since First Death", y = "Reported Daily Deaths", title = "Reported Daily Deaths Over Time") +
  scale_color_manual(values = c("Italy" = "lightblue4", "Spain" = "salmon")) +
  theme_minimal()

```

**Italy:**

- **Growth Rate:** `r round(italy_growth_rate, 3)`

- **Doubling Time:** `r italy_doubling_time` days

**Spain:**

- **Growth Rate:** `r round(spain_growth_rate, 3)`

- **Doubling Time:** `r spain_doubling_time` days


***

# **Question 4**

```{r echo=FALSE, message=FALSE, results='hide'}

# Load the data
milk <- read.csv("milk.csv")
attach(milk)

# Fit a linear regression model to the log-transformed data
milk_model_lm <- lm(log(sales) ~ log(price), data = milk)

# Extract the estimated coefficient for log(price), which corresponds to beta
beta_estimate <- coef(milk_model_lm)['log(price)']


```

**Estimated Price Elasticity of Demand (β):** `r round(beta_estimate, 3)`

In order to estimate the price elasticity based on the economists’ power-law model which is Q = KP^β, I had to perform a logarithmic transformation to linearize the model. After transforming the model using log rules we get log(Q) = log(K) + β⋅log(P). After making a linear model comparing the log of sales compared to the log of price, I looked at the coefficient on the log of price from the linear model which should be the β value or the estimated price elasticity of demand for milk which is about `r round(beta_estimate, 3)`.